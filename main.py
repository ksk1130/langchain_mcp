import os
import gradio as gr
import asyncio
from langchain_openai import ChatOpenAI
from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.prebuilt import create_react_agent

from langchain_mcp_utils import (
    extract_answer,
    get_llm_params,
    initialize_llm,
    load_server_params,
    sync_get_available_tools,
    extract_tool_history,
)

global_client = None
global_tools = []
llm_options = {}


# Gradioç”¨ã®éåŒæœŸãƒãƒ£ãƒƒãƒˆé–¢æ•°
async def gradio_chat(
    user_input, history, function_calling, selected_llm, system_prompt=""
) -> str:
    """
    Gradioã®ãƒãƒ£ãƒƒãƒˆUIã‹ã‚‰å‘¼ã°ã‚Œã‚‹éåŒæœŸãƒãƒ£ãƒƒãƒˆé–¢æ•°ã€‚
    Args:
        user_input (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        history (list): ãƒãƒ£ãƒƒãƒˆå±¥æ­´
        function_calling (str): ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—æœ‰åŠ¹/ç„¡åŠ¹
        selected_llm (str): é¸æŠã•ã‚ŒãŸLLMå
        system_prompt (str): ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    Returns:
        str: ãƒãƒ£ãƒƒãƒˆå¿œç­”
    """
    # é¸æŠã•ã‚ŒãŸLLMã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’åˆæœŸåŒ–
    print("selected_llm:", selected_llm)
    # llm_optionsã‹ã‚‰ã€selected_llmã«å¯¾å¿œã™ã‚‹è¨­å®šã‚’å–å¾—
    llm_config = llm_options.get(selected_llm, {})
    model_name = llm_config.get("model", "gpt-4o")
    base_url = llm_config.get("base_url", "")
    print("model_name:", model_name)

    current_llm = initialize_llm(model_name, base_url)
    # Gradioã®å±¥æ­´(messageså½¢å¼)ã‚’LangChainã®å±¥æ­´ã«å¤‰æ›
    messages = []

    # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒã‚ã‚‹å ´åˆã€æœ€åˆã«è¿½åŠ 
    if system_prompt.strip():
        messages.append({"type": "system", "content": system_prompt.strip()})

    if history:
        for msg in history:
            if msg.get("role") == "user":
                messages.append({"type": "human", "content": msg["content"]})
            elif msg.get("role") == "assistant":
                messages.append({"type": "ai", "content": msg["content"]})
    messages.append({"type": "human", "content": user_input})
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨
    agent_tools = global_tools if function_calling == "æœ‰åŠ¹" else []
    agent = create_react_agent(current_llm, agent_tools, debug=True)
    agent_response = await agent.ainvoke({"messages": messages})
    answer = extract_answer(agent_response)
    # ãƒ„ãƒ¼ãƒ«å±¥æ­´æŠ½å‡º
    tool_history = extract_tool_history(agent_response)
    if tool_history:
        answer += "\n\n[å‘¼ã³å‡ºã•ã‚ŒãŸãƒ„ãƒ¼ãƒ«å±¥æ­´]\n" + "\n".join(tool_history)
    return answer


def sync_gradio_chat(
    user_input, history, function_calling, selected_llm, system_prompt=""
) -> str:
    """
    éåŒæœŸgradio_chaté–¢æ•°ã‚’åŒæœŸçš„ã«å‘¼ã³å‡ºã™ãƒ©ãƒƒãƒ‘ãƒ¼ã€‚
    Args:
        user_input (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        history (list): ãƒãƒ£ãƒƒãƒˆå±¥æ­´
        function_calling (str): ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—æœ‰åŠ¹/ç„¡åŠ¹
        selected_llm (str): é¸æŠã•ã‚ŒãŸLLMå
        system_prompt (str): ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    Returns:
        str: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å›ç­”
    """

    return asyncio.run(
        gradio_chat(user_input, history, function_calling, selected_llm, system_prompt)
    )


async def main() -> None:
    """
    ãƒ¡ã‚¤ãƒ³é–¢æ•°ã€‚Gradioã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·å‹•ã—ã€LLMã¨ãƒ„ãƒ¼ãƒ«ã‚’åˆæœŸåŒ–ã™ã‚‹ã€‚
    """

    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚µãƒ¼ãƒãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
    params_file_name = "server_params.json"
    params = load_server_params(params_file_name)

    # paramsãŒç©ºã®è¾æ›¸ã®å ´åˆ(ï¼è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ)ã€ã‚¨ãƒ©ãƒ¼ã§çµ‚äº†
    if not params:
        print("è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«({})ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€ç„¡åŠ¹ã§ã™ã€‚".format(params_file_name))
        return

    # paramsã‹ã‚‰å¿…è¦ãªæƒ…å ±ã‚’å–å¾—
    global llm_options
    model_name, base_url, llm_options, default_llm, available_llms = get_llm_params(
        params
    )

    # åˆæœŸLLMã®è¨­å®š
    llm = initialize_llm(llm_name=model_name, base_url=base_url)

    # ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«clientã¨toolsã‚’ä¸€åº¦å–å¾—ã—ã¦ä½¿ã„å›ã™
    print("=== MCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ãƒ„ãƒ¼ãƒ«ã‚’åˆæœŸåŒ–ä¸­... ===")

    # ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ãƒ„ãƒ¼ãƒ«ã‚’åˆæœŸåŒ–
    try:
        global global_client
        global_client = MultiServerMCPClient(params.get("servers", {}))
        global global_tools
        global_tools = await global_client.get_tools()
        print(f"åˆæœŸåŒ–å®Œäº†: {len(global_tools)} å€‹ã®ãƒ„ãƒ¼ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã§ã™")

        # ãƒ„ãƒ¼ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º
        for i, tool in enumerate(global_tools, 1):
            tool_name = getattr(tool, "name", "Unknown")
            print(f"  {i}. {tool_name}")
    except Exception as e:
        print(f"ãƒ„ãƒ¼ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        print("ãƒ—ãƒ­ã‚»ã‚¹ã‚’çµ‚äº†ã—ã¾ã™...")
        os._exit(1)  # å³åº§ã«ãƒ—ãƒ­ã‚»ã‚¹ã‚’å¼·åˆ¶çµ‚äº†

    with gr.Blocks(
        theme=gr.themes.Soft(),
        css="""
        .gradio-container {
            height: 100vh !important;
            display: flex !important;
            flex-direction: column !important;
            padding: 0 !important;
            margin: 0 !important;
        }
        .title {
            flex-shrink: 0 !important;
            padding: 10px !important;
            margin: 0 !important;
        }
        .chat-container {
            flex: 1 !important;
            height: calc(100vh - 350px) !important;
            min-height: calc(100vh - 350px) !important;
            max-height: calc(100vh - 350px) !important;
            overflow: auto !important;
        }
        .controls-container {
            flex-shrink: 0 !important;
            padding: 15px !important;
            background: #f8f9fa !important;
            border-top: 1px solid #ddd !important;
            border-bottom: 1px solid #ddd !important;
            min-height: 80px !important;
        }
        .input-container {
            flex-shrink: 0 !important;
            padding: 3px !important;
            margin: 0 !important;
            position: fixed !important;
            bottom: 0 !important;
            left: 0 !important;
            right: 0 !important;
            background: white !important;
            border-top: 1px solid #ddd !important;
            display: flex !important;
            gap: 3px !important;
            align-items: center !important;
        }
        /* 
        .input-container .textbox {
            flex: 1 !important;
            margin: 0 !important;
        }
        .input-container .button {
            flex-shrink: 0 !important;
            width: 60px !important;
            height: 40px !important;
            margin: 0 !important;
        }
        .function-radio {
            position: fixed !important;
            bottom: 60px !important;
            left: 0 !important;
            right: 0 !important;
            border-top: 1px solid #eee !important;
            padding: 10px 20px !important;
            z-index: 10 !important;
            display: flex !important;
            justify-content: flex-end !important;
            align-items: center !important;
            height: 40px !important;
        }
        */
        /* ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®é«˜ã•ã‚’å›ºå®š */
        .chatbot {
            height: calc(100vh - 250px) !important;
            min-height: calc(100vh - 250px) !important;
            max-height: calc(100vh - 250px) !important;
        }
        /* ãƒ—ãƒ«ãƒ€ã‚¦ãƒ³ã¨ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®è¡¨ç¤ºã‚’ç¢ºä¿
        .dropdown, .radio {
            min-height: 40px !important;
            z-index: 1000 !important;
        }*/
        """,
    ) as demo:
        gr.Markdown("# LangChain MCP ãƒãƒ£ãƒƒãƒˆ", elem_classes=["title"])

        # ã‚¿ãƒ–ã§æ©Ÿèƒ½ã‚’åˆ†ã‘ã‚‹
        with gr.Tabs():
            with gr.TabItem("ãƒãƒ£ãƒƒãƒˆ"):
                # ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆï¼ˆç”»é¢ã„ã£ã±ã„ã«è¡¨ç¤ºï¼‰
                chatbot = gr.Chatbot(
                    type="messages",
                    height="calc(100vh - 250px)",
                    elem_classes=["chat-container"],
                    container=True,
                    autoscroll=True,
                    show_copy_all_button=True,
                    show_copy_button=True,
                    resizable=True,
                )

                # functionCallingãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã¨LLMé¸æŠãƒ—ãƒ«ãƒ€ã‚¦ãƒ³
                with gr.Row(elem_classes=["controls-container"]):
                    with gr.Column(scale=1):
                        gr.Markdown("**ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ï¼ˆFunction Callingï¼‰:**")
                        function_radio = gr.Radio(
                            ["æœ‰åŠ¹", "ç„¡åŠ¹"],
                            value="æœ‰åŠ¹",
                            label=None,
                            container=False,
                            elem_classes=["radio"],
                        )
                    with gr.Column(scale=1):
                        gr.Markdown("**ä½¿ç”¨ã™ã‚‹LLM:**")
                        llm_dropdown = gr.Dropdown(
                            choices=available_llms,
                            value=default_llm,
                            label=None,
                            container=False,
                            elem_classes=["dropdown"],
                        )

                # å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
                with gr.Row(elem_classes=["input-container"]):
                    txt = gr.Textbox(
                        show_label=False,
                        placeholder="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...",
                        container=False,
                        scale=9,
                        autofocus=True,
                        submit_btn=True,
                    )
                    send_btn = gr.Button("ğŸ“¤", size="sm", variant="primary", scale=1)

            with gr.TabItem("åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«"):
                # ãƒ„ãƒ¼ãƒ«ä¸€è¦§è¡¨ç¤ºã‚¨ãƒªã‚¢
                tools_display = gr.Markdown(
                    "ã€Œãƒ„ãƒ¼ãƒ«ä¸€è¦§ã‚’æ›´æ–°ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«ã‚’è¡¨ç¤ºã—ã¦ãã ã•ã„ã€‚",
                    height=600,
                )

                # ãƒ„ãƒ¼ãƒ«ä¸€è¦§æ›´æ–°ãƒœã‚¿ãƒ³
                refresh_tools_btn = gr.Button("ğŸ”„ ãƒ„ãƒ¼ãƒ«ä¸€è¦§ã‚’æ›´æ–°", variant="primary")

                def update_tools_display() -> str:
                    """ãƒ„ãƒ¼ãƒ«ä¸€è¦§ã‚’æ›´æ–°ã™ã‚‹é–¢æ•°"""
                    try:
                        tools_info = sync_get_available_tools(global_tools)
                        return tools_info
                    except Exception as e:
                        return f"ãƒ„ãƒ¼ãƒ«ä¸€è¦§ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:\n{str(e)}"

                refresh_tools_btn.click(update_tools_display, outputs=tools_display)

        def user_submit(user_input, history, function_calling, selected_llm) -> tuple:
            """
            Gradioã®é€ä¿¡ã‚¤ãƒ™ãƒ³ãƒˆã‹ã‚‰å‘¼ã°ã‚Œã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã€‚
            ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãƒ»å±¥æ­´ãƒ»functionCallingæœ‰ç„¡ãƒ»é¸æŠã•ã‚ŒãŸLLMã‚’å—ã‘å–ã‚Šã€ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’æ›´æ–°ã™ã‚‹ã€‚
            Args:
                user_input (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
                history (list): ãƒãƒ£ãƒƒãƒˆå±¥æ­´
                function_calling (str): ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—æœ‰åŠ¹/ç„¡åŠ¹
                selected_llm (str): é¸æŠã•ã‚ŒãŸLLMå
            Returns:
                tuple: (ç©ºæ–‡å­—, æ›´æ–°å¾Œå±¥æ­´)
            """
            if not user_input.strip():
                return "", history
            # å†…éƒ¨ã§ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¨­å®š
            system_prompt = """
            ã‚ãªãŸã¯è¦ªåˆ‡ã§çŸ¥è­˜è±Šå¯ŒãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ã€æ­£ç¢ºã§åˆ†ã‹ã‚Šã‚„ã™ã„å›ç­”ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
            ãªãŠã€å›ç­”ã«ã‚ãŸã‚Šã€ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã‚’å®ˆã£ã¦ãã ã•ã„ã€‚
            1. å›ç­”ã¯æ—¥æœ¬èªã§è¡Œã£ã¦ãã ã•ã„ã€‚
            2. å›ç­”ã¯ç°¡æ½”ã§æ˜ç¢ºã«ã—ã¦ãã ã•ã„ã€‚
            3. ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒæœ‰åŠ¹ãªå ´åˆã¯ã€ãƒ„ãƒ¼ãƒ«ã‚’åˆ©ç”¨ã—ã¦ãã ã•ã„ã€‚
            4. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³ã‚’ç†è§£ã—ã‹ã­ã‚‹å ´åˆã¯ã€è¿½åŠ ã®æƒ…å ±ã‚’æ±‚ã‚ã¦ãã ã•ã„ã€‚
            """
            response = sync_gradio_chat(
                user_input, history, function_calling, selected_llm, system_prompt
            )
            # messageså½¢å¼ã«å¤‰æ›
            new_history = history + [
                {"role": "user", "content": user_input},
                {"role": "assistant", "content": response},
            ]
            return "", new_history

        txt.submit(
            user_submit, [txt, chatbot, function_radio, llm_dropdown], [txt, chatbot]
        )
        send_btn.click(
            user_submit, [txt, chatbot, function_radio, llm_dropdown], [txt, chatbot]
        )

    demo.launch(share=False, server_name="127.0.0.1", server_port=7860)


if __name__ == "__main__":
    asyncio.run(main())
